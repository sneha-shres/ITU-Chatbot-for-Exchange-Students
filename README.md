# ITU Chatbot with Vector Database

A modern chatbot interface for the IT University of Copenhagen (ITU) that uses web scraping and vector embeddings to provide intelligent responses about ITU programs, research, and services.

## Features

- ğŸ•·ï¸ **Web Scraping**: Automatically scrapes ITU website content (excluding news)
- ğŸ§  **Vector Database**: Uses FAISS for fast similarity search
- ğŸ¤– **Smart Chatbot**: Provides contextual responses based on ITU knowledge
- ğŸ¨ **Modern UI**: Beautiful, responsive chat interface
- ğŸ” **Semantic Search**: Finds relevant information using embeddings

## Project Structure

```
Chatbot_ITU/
â”œâ”€â”€ app.py                      # Flask backend server
â”œâ”€â”€ scraper.py                  # Web scraper for ITU website
â”œâ”€â”€ vector_db.py                # FAISS vector database implementation
â”œâ”€â”€ sql_store.py                # SQL database storage utilities
â”œâ”€â”€ course_db.py                # Course database interface
â”œâ”€â”€ rag_pipeline.py             # RAG implementation
â”œâ”€â”€ run_scraper.py              # Main script to run everything
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ package.json                # Project configuration
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ RAG_ARCHITECTURE.md         # RAG system documentation
â”‚
â”œâ”€â”€ Courses/                    # Course-related modules
â”‚   â”œâ”€â”€ __pycache__/           # Python cache files
â”‚   â”œâ”€â”€ course_scraper.py      # Course-specific scraper
â”‚   â”œâ”€â”€ csv_to_sqlite.py       # CSV to SQLite converter
â”‚   â”œâ”€â”€ course_pages/          # Scraped course HTML pages
â”‚   â”‚   â””â”€â”€ [144 HTML files]   # Individual course page files
â”‚   â””â”€â”€ output/                # Course data outputs
â”‚       â”œâ”€â”€ courses.csv        # Course data in CSV format
â”‚       â”œâ”€â”€ courses.db         # Course data in SQLite database
â”‚       â”œâ”€â”€ courses.json       # Course data in JSON format
â”‚       â””â”€â”€ read_csv.ipynb     # Jupyter notebook for data analysis
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â””â”€â”€ data_scraper.py        # Additional data scraping utilities
â”‚
â”œâ”€â”€ templates/                  # Flask HTML templates
â”‚   â””â”€â”€ index.html             # Main chat interface
â”‚
â”œâ”€â”€ static/                     # Static assets
â”‚   â”œâ”€â”€ styles.css             # CSS styling
â”‚   â””â”€â”€ script.js              # Frontend JavaScript
â”‚
â”œâ”€â”€ itu_metadata.pkl           # Pickled metadata
â”œâ”€â”€ itu_scraped_data.json      # Scraped ITU website data
â”œâ”€â”€ itu_scraped_urls.txt       # List of scraped URLs
â””â”€â”€ itu_vector_index.faiss     # FAISS vector index file
```

## Installation

1. **Clone or download the project**
2. **Create a virtual environment:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## Usage

### 1. Scrape ITU Website and Build Vector Database

```bash
python run_scraper.py
```

This will:
- Scrape ITU website (excluding news pages)
- Create embeddings using sentence transformers
- Build FAISS vector database
- Test the search functionality

### 2. Start the Chatbot

```bash
python app.py
```

Then open your browser and go to: `http://localhost:5000`

## API Endpoints

- `GET /` - Main chatbot interface
- `POST /api/chat` - Send messages to chatbot
- `GET /api/health` - Health check
- `GET /api/history` - Get conversation history
- `POST /api/search` - Search knowledge base
- `GET /api/database/stats` - Get database statistics

## Example Questions

Try asking the chatbot:

- "What computer science programs does ITU offer?"
- "How do I apply for admission?"
- "What research opportunities are available?"
- "Tell me about student life at ITU"
- "What are the admission requirements?"

## Configuration

### Scraper Settings

In `scraper.py`, you can modify:
- `max_pages`: Number of pages to scrape (default: 30)
- `base_url`: ITU website URL
- News filtering: Automatically skips news pages

### Vector Database Settings

In `vector_db.py`, you can modify:
- `model_name`: Sentence transformer model (default: "all-MiniLM-L6-v2")
- `max_length`: Text chunk size (default: 512)
- `k`: Number of search results (default: 5)

## Technologies Used

- **Backend**: Flask, Python
- **Web Scraping**: BeautifulSoup, Requests
- **Vector Database**: FAISS
- **Embeddings**: Sentence Transformers
- **Frontend**: HTML, CSS, JavaScript
- **Styling**: Modern CSS with gradients and animations

## Notes

- The scraper respects robots.txt and includes delays between requests
- News pages are automatically filtered out to focus on core content
- The vector database is built locally and can be reused
- All scraped data is saved as JSON for inspection

## Troubleshooting

1. **Import errors**: Make sure all dependencies are installed
2. **Scraping issues**: Check internet connection and ITU website availability
3. **Vector database errors**: Ensure sufficient disk space for embeddings
4. **Port conflicts**: Change port in `app.py` if 5000 is occupied

## License

MIT License - feel free to use and modify as needed.